#!/usr/bin/env python3

"""

run_surface.py -- compute surface echo powers
See README.md for general usage help among processing scripts

"""

__authors__ = ['Cyril Grima, cyril.grima@gmail.com']
__version__ = '1.0'
__history__ = {
    '1.0':
        {'date': 'March 13 2019',
         'author': 'Cyril Grima, UTIG'}}

import logging
import argparse
import os
import sys
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

import SHARADEnv
from run_rng_cmp import add_standard_args, should_process_products, process_product_args

import rsr




def rsr_processor(orbit, typ='cmp', gain=0, sav=True,
    senv=None, **kwargs):
    """
    Output the results from the Radar Statistical Reconnaissance Technique
    applied along a SHARAD orbit

    Inputs
    -----

    orbit: string
        the orbit number or the full name of the orbit file (w/o extension)
        if the orbit is chunked in several files
    typ: string
        the type of radar data used to get the amplitude from
    gain: float
        Any gain to be added to the signal (power in dB)
        For SHARAD, it includes the instrumental gain and the absolute
        calibration value
    save: boolean
        Whether to save the results in a txt file into the hierarchy
    senv: SHARADEnv
        A SHARADEnv environment object
    Any keywords from rsr.utils.inline_estim, especially:

    fit_model : string
        pdf to use to estimate the histogram statistics (inherited from rsr.fit)
    bins : string
        method to compute the bin width (inherited from astroML.plotting.hist)
    inv : string
        inversion method (inherited from rsr.invert)
    winsize : int
        number of amplitude values within a window
    sampling : int
        window repeat rate
    verbose : bool
        Display fit results informations

    Output
    ------
    Results are gathered in a pandas Dataframe that inherits from some of the
    auxilliary data plus the following columns:
    xa: First x-coordinate of the window gathering the considered amplitudes
    xb: Last x-coordinate of the window gathering the considered amplitudes
    xo: Middle x-coordinate of the window gathering the considered amplitudes
    pt: Total power received at the antenna
    pc: Coherent power received at the antenna
    pn: Incoherent power received at the antenna
    crl: Coefficient correlation of the RSR fit
    chisqr: Chi-square of the RSR fit
    mu: HK structure parameter
    ok:  Whether the RSR fit converged correctly (1) or not (0)
    """

    assert senv is not None

    # This should be done in aux_data?
    orbit_full = orbit if orbit.find('_') == 1 else senv.orbit_to_full(orbit)

    # Surface amplitudes
    surf = pd.DataFrame(senv.srf_data(orbit_full))

    # Surface coefficients (RSR)
    logging.debug('PROCESSING: Surface Statistical Reconnaissance for %s', orbit_full)
    b = rsr.run.along(surf['surf_amp'].values, **kwargs)

    # Reformat results
    xo = b['xo'].values.astype(int)# along-track frame number
    for key in surf.keys():
        b[key] = surf[key].to_numpy()[xo]

    b = b.rename(index=str, columns={"flag":"ok"})

    # Work-around for pandas' bug "ValueError: Big-endian buffer not supported
    # on little-endian compiler"
    b = pd.DataFrame(np.array(b).byteswap().newbyteorder(), columns=b.keys())

    # Archive
    # TODO: make this a separate function (should it be a member of SHARADEnv?)
    # archive_rsr(senv, orbit, rsr_data)
    if sav: # == True:
        fil = senv.sfiles.product_paths('rsr', orbit_full)['rsr_txt']
        os.makedirs(os.path.dirname(fil))
        b.to_csv(fil, index=None, sep=',')
        logging.debug("CREATED: %s", fil)

        # TODO: save debugging output if requested
        if False:
            # Debugging output
            outfile = str(Path(fil).with_suffix('.npy'))
            logging.debug("Saving debug to " + outfile)
            np.save(outfile, b)



    return b


def rsr_grid(filename:str, query_lon=None, query_lat=None, grid_shape='square',
             r=np.rad2deg(5/3389.5), nbcores=8, senv=None):
    """
    Output the results from the Radar Statistical Reconnaissance Technique
    applied over a spatial grid of covering a set of surface amplitudes.

    Inputs
    -----
    filename: string
        hdf5 file of srf data generated by
        SHARADEnv.gather_datapoints
    radius: float
        radius around each point
    """
    assert senv is not None

    # Load and select data
    #quadrangle_id = filename[filename.find('MC'):filename.find('MC')+4]
    #quadrangle = senv.quadrangle(quadrangle_id, orbitlist=False)

    data = pd.read_hdf(filename, key='srf',
                       columns=['surf_amp', 'SUB_SC_EAST_LONGITUDE',
                       'SUB_SC_PLANETOCENTRIC_LATITUDE'],
                       where='(surf_amp > 0) & (flag == 0) & '+
                       '((SC_ROLL_ANGLE > -.5) & (SC_ROLL_ANGLE < .5) | '+
                       '(SC_ROLL_ANGLE > 179.5) & (SC_ROLL_ANGLE < 180.5))'
                      )

    data.replace([np.inf, -np.inf], np.nan, inplace=True)
    data.dropna(inplace=True)

    # Make a grid
    logging.info("Making grid coordinates for " + filename)
    if not query_lon or not query_lat:
        xlim = [np.min(data['SUB_SC_EAST_LONGITUDE']),
                np.max(data['SUB_SC_EAST_LONGITUDE'])]
        ylim = [np.min(data['SUB_SC_PLANETOCENTRIC_LATITUDE']),
                np.max(data['SUB_SC_PLANETOCENTRIC_LATITUDE'])]
        query_lon, query_lat = rsr.utils.grid_coordinates(r, xlim, ylim,
                                                          shape=grid_shape)

    # Launch rsr
    logging.info("Processing RSR for %d locations on the grid"
                 " (this could take a while)", len(query_lon))
    out = rsr.run.incircles(data['surf_amp'], data['SUB_SC_EAST_LONGITUDE'],
                            data['SUB_SC_PLANETOCENTRIC_LATITUDE'],
                            query_lon, query_lat, r, nbcores=nbcores)

    # Format data
    out['lon'] = [query_lon[int(i)] for i in out['ID'].values]
    out['lat'] = [query_lat[int(i)] for i in out['ID'].values]

    # Store data
    out.to_csv(os.path.splitext(filename)[0] + '.rsr.csv', sep=',', header=True, index=False)

    return out



def rsr_quadrangle(filename, query_lon=None, query_lat=None, grid_shape='square',
                  r=np.rad2deg(5/3389.5), nbcores=8, senv=None):
    """
    Output the results from the Radar Statistical Reconnaissance Technique
    applied over a spatial grid of surface amplitudes covering a
    specific Martian quadrangle.

    Inputs
    -----
    filename: string
        hdf5 file of srf data generated by
        SHARADEnv.gather_datapoints_quadrangle
    radius: float
        radius around each point
    """
    assert senv is not None

    # Load and select data
    quadrangle_id = filename[filename.find('MC'):filename.find('MC')+4]
    quadrangle = senv.quadrangle(quadrangle_id, orbitlist=False)

    data = pd.read_hdf(filename, key='srf',
                       columns=['surf_amp', 'SUB_SC_EAST_LONGITUDE',
                       'SUB_SC_PLANETOCENTRIC_LATITUDE'],
                       where='(surf_amp > 0) & (flag == 0) & '+
                       '((SC_ROLL_ANGLE > -.5) & (SC_ROLL_ANGLE < .5) | '+
                       '(SC_ROLL_ANGLE > 179.5) & (SC_ROLL_ANGLE < 180.5))'
                      )

    data.replace([np.inf, -np.inf], np.nan, inplace=True)
    data.dropna(inplace=True)

    # Make a grid
    logging.info("Making grid coordinates for " + filename)
    if not query_lon or not query_lat:
        xlim = quadrangle['lon']
        ylim = quadrangle['lat']
        query_lon, query_lat = rsr.utils.grid_coordinates(r, xlim, ylim,
                                                          shape=grid_shape)

    # Launch rsr
    logging.info("Processing RSR for %d locations on the grid"
                 " (this could take a while)", len(query_lon))
    out = rsr.run.incircles(data['surf_amp'], data['SUB_SC_EAST_LONGITUDE'],
                            data['SUB_SC_PLANETOCENTRIC_LATITUDE'],
                            query_lon, query_lat, r, nbcores=nbcores)

    # Format data
    out['lon'] = [query_lon[int(i)] for i in out['ID'].values]
    out['lat'] = [query_lat[int(i)] for i in out['ID'].values]

    # Store data
    out.to_csv(os.path.splitext(filename)[0] + '.rsr.csv', sep=',', header=True, index=False)

    return out


def main():
    parser = argparse.ArgumentParser(description='RSR processing routines')

    #--------------------
    # Job control options
    add_standard_args(parser, script='rsr')

    #--------------------
    # Algorithm options

    parser.add_argument('-w', '--winsize', type=int, default=1000,
            help='Number of consecutive echoes within a window where statistics\
            are determined')
    parser.add_argument('-s', '--sampling', type=int, default=250,
            help='Step at which a window is repeated')
    parser.add_argument('-y', '--ywinwidth', nargs='+', type=int, default=[-100,100],
            help='Number of samples defining the fast-time relative boundaries around\
            the altimetry surface return where the surface will be looked for')
    parser.add_argument('-b', '--bins', type=str, default='fd',
            help='Method to compute the bin width (inherited from numpy.histogram)')
    parser.add_argument('-f', '--fit_model', type=str, default='hk',
            help='Name of the function (in rsr.pdf module) to use for the fit')


    args = parser.parse_args()

    loglevel=logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=loglevel, stream=sys.stdout,
        format="run_rsr: [%(levelname)-7s] %(message)s")

    if args.output is None:
        args.output = os.path.join(args.SDS, 'targ/xtra/SHARAD')

    orig_path = os.path.join(args.SDS, 'orig/supl/xtra-pds/SHARAD')
    senv = SHARADEnv.SHARADEnv(data_path=args.output, orig_path=orig_path, b_index_files=False)
    ## add sfiles and pass through to figure out output file location
    #--------------------------
    # Requested Orbits handling

    if args.orbits == ['all']:
        # Get all known product IDs from the index
        productlist = senv.sfiles.product_id_index.keys()
    else:
        senv.index_files(use_edr_index=True, index_intermediate_files=False)
        productlist = process_product_args(args.orbits, args.tracklist, senv.sfiles)
    assert productlist, "No files to process"

    process_list = []
    ii = 0
    for ii, product_id in enumerate(productlist, start=1):
        try:
            infiles = senv.sfiles.product_paths('srf', product_id)
            outfiles = senv.sfiles.product_paths('rsr', product_id)
        except KeyError: # pragma: no cover
            logging.debug("Can't find product ID %s in index for srf, rsr", product_id)
            continue

        if not should_process_products(product_id, infiles,  outfiles, args.overwrite):
            continue

        process_list.append(product_id)

    if args.maxtracks > 0 and len(process_list) > args.maxtracks:
        process_list = process_list[0:args.maxtracks]

    #-----------
    # Processing

    logging.info("Processing %d orbits of %d requested", len(process_list), ii)

    if args.dryrun:
        logging.info("Process orbits: %s", ' '.join(productlist))
        return

    for i, product_id in enumerate(process_list, start=1):
        logging.info('(%s) %5d/%5d: %s', datetime.now().strftime('%Y-%m-%d %H:%M:%S'), i, len(process_list), product_id)
        b = rsr_processor(product_id, winsize=args.winsize, sampling=args.sampling,
                nbcores=args.jobs, verbose=args.verbose,
                bins=args.bins, fit_model=args.fit_model, sav=True,
                senv=senv)


if __name__ == "__main__":
    # execute only if run as a script
    sys.exit(main())

